This is where everything important is. 

1. Subject data folders
	a. Fresh Subject Data - Unprocessed Data
	b. sub-0x - folders corresponding to each subject that was scanned. There are more deeper folders in each of these, but they are all parallel to each other. See sub-01 for details on how to navigate each folder. 

2. Importance maps folders
	When the MVPA script runs, there is an option to export importance maps. These are kind of like masks with voxel values based on the parameter weight of the voxel multiplied with the average activity in that voxel. Basically, it's a good way to see what areas the classifier is using to make its decisions. I used the positive .hdr files visualized in MRIcroGL to make figures for my thesis. Also, I calculated some masks which are in the folder literally called maps generated by me.

3. Masks
	These are masks which isolate specific regions of the brain for use in the classifier. They are created using the wfupickatlas utility of spm. I grabbed some Brodmann areas, put them together, and used some combinations of those to get my results. 

4. MRIcroGL processing
	This is actually just a whole bunch of redundant information from other folders. I made copies when I was putting together report 1 mostly for the purpose of making it easier to navigate the file structure for image generation.

5. mvpa_output_files
	This is where the mvpa script dumps the results of running each subject. If you open the file, it imports the res structure in the variables workspace of matlab. This lets you see the accuracy, confusion matrix, predictions vs real values by trial, all sorts of stuff. To get deep into the structure, you first click 'subj' and then there's quite a peculiar bug. When matlab creates the next layer deep, it's a bunch of blank cells. You have to click the cell in row 1, column (sub_no) to get to the next depth level. Then you just keep clicking the 1,1 cell until you get where you want. I have no idea why this saves like this, but I do know how to work around it.

6. raw_data
	Unprocessed data from Google Drive.

7. sourcedata
	Different unprocessed data, I don't know I never touched it

8. EventsConcatenator
	A simple script I made which combines the events.tsv files from each subject's 4 runs into one long events file

9. Label Scrambler
	A script which scrambles the labels of each trial to essentially be nonsensical. This is done to run a random permutation model of the study and establish what true random chance prediction is.

10. ModelFileGenerator
	Basically turns the events file into a matlab variable to integrate with the mvpa script. Creates a structure with the names of trial types, onsets of trial iterations, and durations of trial iterations (although this is set to 0 as it isn't used in my study).

11. RenamingScript
	All the preprocessing steps in spm add a whole bunch of prefixes and the original names of the files are also silly, so I made this to simplify the 3D scan filenames to "run_001" or something. This makes the files more readable and easier to work with in the code.

